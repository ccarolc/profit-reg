---
title: "Modelagem via regressão linear do lucro de Startups"
author:  
- Caroline Cogo Carneosso^[carolcogo808@gmail.com]
header-includes:
   - \usepackage[brazil]{babel}
   - \usepackage{bm}
   - \usepackage{float}
date: "`r format(Sys.time(), '%B %Y')`" #mes e ano automat,%m sai o n do mes
geometry: left=1.7cm, right=1.7cm, top=3cm, bottom=3cm
output:
  bookdown::pdf_document2:
    includes:
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: 72
indent: true
toc: True
bibliography: bib.bib 
csl: style.csl
nocite: '@*'
link-citations: true
---
```{=tex}
\clearpage
```

```{r setup,include=F}
# pacotes uteis
library(hnp) # pacote para envelope simulado
library(lmtest) # teste reset
library(car) # para teste de multicolinearidade (fatores de inflacao de variancia)
library(tseries) # teste de Jarque-Bera
library(tidyverse)
library(mypdf1)
library(patchwork) #colocar os graf um do lado do outro

knitr::opts_chunk$set(
	echo = FALSE,
	error = F,
	fig.align = "center",
	fig.height = 4, #altura
	fig.pos = "H",
	fig.width = 7.5, #largura
	message = FALSE,
	warning = FALSE
)
#widht=largura

options(scipen=999) #desabilita result em notação científica 
options(digits=3)
options(OutDec=".")
```

```{r funções}

graph=function(df,l){
  df %>% 
    as_tibble() %>% 
      ggplot(aes(as.numeric(row.names(df  %>% as_tibble())),value))+
      geom_point(color="red")+
      geom_hline(yintercept=l, linetype="dashed", color = "navy")+
      geom_hline(yintercept=-l, linetype="dashed", color = "navy")+
      labs(x="Índice")
    
}
graph2=function(df,l){
  df %>% 
    as_tibble() %>% 
      ggplot(aes(as.numeric(row.names(df  %>% as_tibble())),value))+
      geom_point(color="red")+
      geom_hline(yintercept=l, linetype="dashed", color = "navy")+
      labs(x="Índice")
    
}
```


# Introdução

Startup é uma empresa inovadora com custos de manutenção muito baixos, mas que consegue crescer rapidamente e gerar lucros cada vez maiores. Além disso, possui um modelo de negócios repetível, escalável, em um cenário de incertezas e soluções a serem desenvolvidas. Assim, a proposta do presente trabalho é definir um modelo de regressão linear que seja capaz de predizer a variável y, e quanto as covariáveis influenciam na média de y. Para a validação deste modelo será utilizado critérios de seleção, gráficos para a análise de diagnóstico e influência, tais como: alavancagem, distância de Cook, envelope simulado, entre outras técnicas gráficas.

```{r, include=FALSE}
## Importando os dados
dados<- read.csv("50_Startups.csv",h=T) |> 
  mutate(State=as.factor(State))

dados<-dados |> 
  rename(rdspend=R.D.Spend,adm=Administration,mkt=Marketing.Spend,
         profit=Profit,estado=State)

head(dados)
attach(dados)

## Variaveis:
#Research and development spend 
#Administration
#marketing spend
#profit= lucro da empresa/startup
#state
# A ideia eh modelar y, no caso profit, em funcao das demais
```

O banco de dados é referente a detalhes da receita de 50 Startups dos estados de New York, California e Florida, disponível na plataforma Kaggle e pode ser acessado clicando [\textcolor{red}{aqui}](https://www.kaggle.com/datasets/karthickveerakumar/startup-logistic-regression). 

\begin{table}[H]
\caption{Descrição da váriaveis}\label{tab:tab0}
\centering
\begin{tabular}[t]{l|c}
\hline
Variável & Descrição\\
\hline
$y$ profit & Lucro total da Startup\\
\hline
$x_{1}$ adm & Gastos com Administração\\
\hline
$x_{2}$ rdspend & Gastos com Pesquisa e Desenvolvimento\\
\hline
$x_{3}$ mkt & Gastos com Marketing\\
\hline
$x_{4}$ estado & Estado da Startup, New York, California ou Florida \\
\hline
\end{tabular}
\end{table}

Para fins de interpretação vamos considerar os valores em dólares. O banco de dados possui `r nrow(dados)` observações e `r ncol(dados)` variáveis, que estão descritas na Tabela \@ref(tab:tab0). Além disso, foram criadas 2 variáveis dummies para a variável categórica estado, utilizando o estado da California como base, ou seja, foram acrescentadas as covariáveis: estadoFlorida e estadoNew York.

```{r, include=F}
#profit~adm+rdspend+mkt+estado
var = c(' $y$ profit', '$x_{1}$ adm', '$x_{2}$ rdspend', '$x_{3}$ mkt', '$x_{4}$ estado')
desc = c('Lucro', 'Administração', 'Pesquisa e Desenvolvimento',
         'Marketing', 'Estados')

data.frame(Variável = var, Descrição = desc) |> 
  mypdf1::pdf1_tbl("Descrição da variáveis", format = "latex")
```

# Análise descritiva

Podemos avaliar pela Tabela \@ref(tab:tab1), um resumo das variáveis, com as medidas descritivas, contendo o valor mínimo, 1º quantil, mediana, valor médio, 3º quantil e valor máximo. É importante ressaltar, que a variável de desfecho lucro, para as 50 startups do banco de dados, apresentou menor lucro de 14 681 dólares e lucro máximo de
192 262 dólares.

```{r tab1, include=TRUE, results='asis'}
 summary(dados, digits = 2) |> 
  mypdf1::pdf1_tbl("Análise descritiva das variáveis.")
  
```

É importante examinar a correlação entre as covariáveis, pois devemos ter uma correlação "aceitável" entre a variável resposta e as covariáveis, o que entretanto, não pode acontecer entre as covariáveis, pois afeta negativamente o método de mínimos quadrados ordinários.

```{r tab2, include=TRUE}
dados |> 
  select_if(is.numeric) |> 
  cor() |> 
  mypdf1::pdf1_tbl("Correlação entre as variáveis.")# correlacao
```

Notamos pela Figura \@ref(fig:fig1) e Tabela \@ref(tab:tab2) que Gastos com Marketing (mkt) e Gastos com Pesquisa e Desenvolvimento (rdspend) possuem uma correlação alta o que pode afetar a suposição [S4]. Além disso, existe uma correlação alta e positiva de 0.97 entre o lucro (profit) e o Gastos com Pesquisa e Desenvolvimento (rdspend), ou seja, quanto maior o gasto em pesquisa e desenvolvimento, maior será o lucro.

```{r fig1, fig.cap="Gráfico de dispersões"}
plot(dados[,-4]) # diagrama de dispersao
```

# Modelo inicial

Agora que já fizemos uma análise inicial das variáveis do estudo, apresenta-se o modelo inicial abaixo, contendo todas as variáveis.

$$
y = \beta_{0} + \beta_{1}x_{1} + \beta_{2}x_{2} + \beta_{3}x_{3} + \beta_{4}x_{4}+\epsilon.
$$
Em que $\beta_{0}$ é o intercepto do modelo, $y$ é a variável resposta, lucro da Startup, e o vetor de covariáveis $(x_{1},x_{2},x_{3},x_{4})^T$, foram descritas na Tabela \@ref(tab:tab0).

No modelo inicial, através do teste t, apenas o intercepto e $x_{2}$ possui significância a um nível de $5\%$, como pode ser visto na Tabela \@ref(tab:modinicial). O modelo apresenta coeficiente de determinação (R2) de 0.951, e R2 ajustado $(\bar{R2})$ de 0.945.

```{r, results='hide'}
fit0<-lm(profit~adm+rdspend+mkt+estado, data = dados)
summary(fit0)

step(fit0)
#pelo step seleciona rdspend, mkt

#RETIRANDO as outras variaveis 
fit<-lm(profit~rdspend+mkt, data = dados)
summary(fit)

dados45<-dados[c(-47,-50),]

## ajustando o modelo
fit50<- lm(profit~adm+rdspend+mkt+estado,data=dados45)
summary(fit50)

step(fit50)
#deu significativo por step, rdspend e mkt

fit<-lm(profit~rdspend+mkt, data = dados45)
summary(fit)

# Verifique R2, R2-ajustado, teste F e testes t
# Mas note que soh podemos "acreditar" nesses testes apos analise de 
# diagnostico e os varios testes estudados. Veja a seguir.
```

```{r modinicial, include=TRUE}
fit0<-lm(profit~adm+rdspend+mkt+estado, data = dados)
a<-summary(fit0)
a$coefficients |>
  as.data.frame() |> 
  rename(p.value = "Pr(>|t|)") |>
  mutate(p.value = case_when(
    p.value <= 0.001 ~ "0.001***",
    (0.001 < p.value & p.value <= 0.01) ~ "0.01**",
    (0.01 < p.value & p.value <= 0.05) ~ "0.01*",
    TRUE ~ as.character(round(p.value, 3))
  )) |>
  mypdf1::pdf1_tbl("Coeficientes para o modelo inicial") |> 
  kableExtra::footnote(general = "Signif. codes 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 ",footnote_as_chunk = T, title_format = c("italic", "underline")) 

```

Entretanto, ao aplicar o método de Stepwise, através da função $step$ do software $R$ que analisa através do critério de informação de Akaike (AIC) o melhor modelo a ser proposto, e retira possíveis covariáveis não explicativas, o método selecionou como significativa o intercepto e as covariáveis $x_{2}$ e $x_{3}$. 

# Modelo ajustado

Após sucessivas aplicações da função $step$, testando as combinações das covariáveis e diversas análises, de pontos influentes e gráficas, chegamos ao modelo ajustado apresentado abaixo.

$$
y = \beta_{0} + \beta_{2}x_{2} + \beta_{3}x_{3}+\epsilon.
$$
Na Tabela \@ref(tab:modfinal), o intercepto e todas as covariáveis foram significativas $(x_{2}, x_{3})$, para isso foi necessário retirar as observações 47 e 50 do banco de dados original.

```{r, include=F, results='hide'}
dados45<-dados[c(-47,-50),]

## ajustando o modelo
fit50<- lm(profit~adm+rdspend+mkt+estado,data=dados45)
summary(fit50)

step(fit50)
#deu significativo por step, rdspend e mkt

fit<-lm(profit~rdspend+mkt, data = dados45)
summary(fit)
```

```{r modfinal, include=TRUE}
fit<-lm(profit~rdspend+mkt, data = dados45)
b<-summary(fit)
# b$coefficients |>
#   as.data.frame() |> 
#   mutate(`Pr(>|t|)`=format.pval(`Pr(>|t|)`,eps = 0.01)) |> 
#   mypdf1::pdf1_tbl("Coeficientes do Modelo ajustado") |> 
#   kableExtra::footnote(general = "Signif. codes 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 ",footnote_as_chunk = T, title_format = c("italic", "underline"))


b$coefficients |>
  as.data.frame() |>
  rename(p.value = "Pr(>|t|)") |>
  mutate(p.value = case_when(
    p.value <= 0.001 ~ "0.001***",
    (0.001 < p.value & p.value <= 0.01) ~ "0.01**",
    (0.01 < p.value & p.value <= 0.05) ~ "0.01*",
    TRUE ~ as.character(round(p.value, 3))
  )) |>
  mypdf1::pdf1_tbl("Coeficientes para o modelo ajustado") |>
  kableExtra::footnote(general = "Signif. codes 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 ",footnote_as_chunk = T, title_format = c("italic", "underline"))

```

# Análise de diagnóstico e influência

```{r, include=F}
n<-dim(dados45)[1] # tamanho da amostra

g0<-hatvalues(fit) |> 
  graph2(2*(fit$rank/n))+
  labs(x="Índice", y="Alavancagem")

g1<-cooks.distance(fit) |> 
graph2(4/(n-fit$rank))+
  labs(x="Índice",y="Distância de Cook")

g2<-dffits(fit) |> 
 graph(2*sqrt(fit$rank /n))+
  labs(title="Dffits",x="Índice",y="Dffits")   
dfbetas(fit)# cada beta tem seu DF

g3<-dfbetas(fit)[,1] |> 
  graph(limite<-2/sqrt(n))+
  labs(title ="Dfbeta 1",x="Índice", y="Dfbeta 1")

g4<-dfbetas(fit)[,2] |> 
  graph(limite<-2/sqrt(n))+
  labs(title ="Dfbeta 2",x="Índice", y="Dfbeta 2")

g5<-dfbetas(fit)[,3] |> 
  graph(limite<-2/sqrt(n))+
  labs(title ="Dfbeta 3",x="Índice", y="Dfbeta 3")

residuo <- rstudent(fit)
g6<-residuo |> 
  graph(3)+
  labs(title ="Resíduos", x="Índice", y="Resíduos")

g7<-residuo |> 
  tibble::tibble() |> 
  ggplot(aes(residuo))+geom_histogram(bins = 6,fill="white", colour="black")+
  labs(x="Resíduo",title="Histograma dos resíduos")

#hist(residuo) # histograma dos residuos
```

```{r fig2, include=TRUE, fig.cap="Gráfico para a alavancagem", fig.height=3.5, fig.width=6.5}
g0
```
```{r fig3,include=TRUE, fig.cap="Gráfico para a Distância de Cook", fig.height=3.5, fig.width=6.5}
g1
```
```{r fig4, include=TRUE, fig.cap="Gráficos para o DFFIT e Dfbeta"}
g2+g3

```
```{r fig6, include=TRUE, fig.cap="Gráficos para os Dfbetas"}
g4+g5
```

```{r fig5, include=TRUE, fig.cap="Gráficos para o resíduo e histograma"}
g6+g7
```
```{r env, include=T, results='hide', fig.cap="Gráfico de Envelope Simulado", fig.height=3.8, fig.width=6.7}
# envelope simulado baseado nos residuos studentizados
#hnp(fit,resid.type="student",halfnormal = F) # envelope simulado 

residuo %>% 
  as_tibble() %>% 
  ggplot(aes(sample = value)) +
  qqplotr::geom_qq_band(alpha = 0.5, fill="white", col="black",B=150,bandType = "boot") +
  qqplotr::stat_qq_line(size=0.5, linetype="dashed") + 
  qqplotr::stat_qq_point(size=1.3) +
  scale_fill_discrete("Bandtype")+
  labs(x = "Quantis teóricos", y = "Resíduos")
```

Previamente, foi realizada a análise de influência, foram retiradas do banco de dados as observações 47 e 50, que se mostraram discreprantes das demais, e estavam interferindo na modelagem. 

Na Figura \@ref(fig:fig2), temos o gráfico das medidas de alavancagem, que  informam se uma observação é discrepante em termos de covariável, nota-se que apenas duas observações estão um pouco fora dos limites pré-estabelecidos.

Através da Figura \@ref(fig:fig3), observa-se o gráfico com a distância de Cook, que fornece a influência de cada observação $i$ sobre todos os $n$ valores ajustados, há alguns pontos fora do limite, porém não são discrepantes dos demais.

Por meio da Figura \@ref(fig:fig4), temos o gráfico dos Dffits que considera o grau de influência que a observação $i$ tem sobre o valor seu próprio valor ajustado $\hat{y_i}$. Na Figura \@ref(fig:fig4) e  \@ref(fig:fig6), visualizamos os gráficos para os Dfbetas, que medem a influência da observação $i$ sob as estimativas de cada $\beta$. Em ambas as figuras, não percebemos nenhum ponto claramente influente.

Ao visualizar, a Figura \@ref(fig:fig5), temos o gráfico dos resíduos, onde percebe-se que todos as observações estão dentro do limite de 3 desvios padrões, e também o histograma, onde nota-se que os resíduos se assemelham a uma distribuição normal.

Na Figura \@ref(fig:env), temos o envelope simulado baseado nos resíduos studentizados, com todas as observações dentro das bandas de confiança, o que sinaliza que a distribuição normal é adequada para o modelo.

# Suposições do modelo

Para que o modelo seja validado é necessário confirmar as seguintes suposições através de testes de hipóteses.


-   [S0] O modelo está corretamente especificado.

-   [S1] A média dos erros é zero.

-   [S2] Homoscedasticidade dos erros.

-   [S3] Não há autocorrelação.

-   [S4] Ausência de multicolinearidade.

-   [S5] Normalidade dos erros.

Para testes de hipóteses, se $\alpha>p-valor$, então rejeita-se a hipótese nula (**H0**).

```{r, include=FALSE}
s0<-resettest(fit)
s1<-t.test(residuo,mu=0,alternative="two.sided")
s2<-bptest(fit, studentize = TRUE)
s3<-dwtest(fit)
s4<-vif(fit)
s5<-jarque.bera.test(residuo)

```

\subsection{Teste para a [S0]}

Teste RESET de especificação sob **H0**: O modelo está corretamente
especificado. Com p-valor igual a `r s0$p.value`, ao nível de significância igual a $\alpha=0.05$, não rejeitamos **H0**. Logo, não há evidências de incorreta especificação do modelo.

\subsection{Teste para a [S1]}

Teste t para a média dos errros sob **H0**: média dos erros é igual a zero. Com p-valor igual a `r s1$p.value`, ao nível de significância igual a $\alpha=0.05$, conclui-se que não rejeitamos **H0**. Logo, a média dos erros é igual a zero.

\subsection{Teste para a [S2]}

Teste de Bressch-Pagan (Koenker) de Heteroscedasticidade sob H0: erros são
homoscedásticos. Com p-valor igual a `r s2$p.value`, ao nível de significância igual a $\alpha=0.05$, conclui-se que não rejeitamos **H0**. Logo, os erros são
homoscedásticos.

\subsection{Teste para a [S3]}

Teste de Durbin-Watson de autocorrelação sob **H0**: não há autocorrelação. Com p-valor igual a `r s3$p.value`, ao nível de significância igual a
$\alpha=0.05$, conclui-se que rejeitamos **H0**. Logo, através do teste, concluimos que há autocorrelação. Entretanto, pode se ver através do gráfico da Figura \ref{fig:acf}, que não existe autocorrelação já que todos os lags são não significativos, ou seja, dentro das bandas de confiança. Assim sendo, vamos considerar a não existência de correlação e a verificação da S3.

```{r acf, fig.cap="Gráfico da função de autocorrelação", include=TRUE, fig.height=3.5, fig.width=6.5}

acf(rstudent(fit),lag.max=50)
```

\subsection{Teste para a [S4]}

Usa-se Fatores de Inflação de Variância (VIF) para detectar multicolinearidade. Em que, VIF \> 10 indica multicolinearidade e VIF=1 seria o ideal.

```{r tab30, include=TRUE}
s4 |> pdf1_tbl("Fatores de Inflação de Variância para as variáveis do modelo ajustado.")
```

Percebe-se pela Tabela \ref{tab:tab30}, que o valor está próximo a
1, para $x_{2}$ e $x_{3}$. Logo, não há multicolinearidade. 

\subsection{Teste para a [S5]}

Teste Jarque-Bera de Normalidade, **H0**: Os erros possuem distribuição
normal. Com p-valor igual a `r s5$p.value`, ao nível de significância igual a
$\alpha=0.05$, conclui-se que não rejeitamos **H0**. Logo, não existem indícios de não normalidade dos erros.

# Modelo final

Agora com o modelo checado, com boas evidências de que as suposições
estão satisfeitas, é possivel fazer interpretações.
O modelo apresentou $R2=0,96$, cerca de $96\%$ da variação de y, é
explicado pelas covariáveis, ou seja, $96\%$ da variação da média do lucro das Startups é explicada por $x_{2}$ e $x_{3}$, gastos com pesquisa e desenvolvimento e gastos em marketing, respectivamente. Além disso, o critério de seleção do modelo é de $(\bar{R2})$ ajustado igual a 0,959.


$$
y = 50172.0465+0.7512 x_{2}+0.0353x_{3}.
$$

Nota-se que as covariáveis influenciam positivamente na média de $y$, e o intercepto também. Para a covariável $x_{2}$, a cada 1 dólar gastos com pesquisa e desenvolvimento, adiciona-se 0.75 dólares no lucro da Startup, para a covariável $x_{3}$, a cada 1 dólar gastos com marketing, adiciona-se 0.03 doláres no lucro da Startup.

# Conclusão

Portanto, O estudo propôs um modelo de regressãao linear para o banco de dados de 50 Startups, contendo como variável resposta o Lucro e como covariáveis Gastos com Administração, Gastos com Pesquisa e Desenvolvimento, Gastos com Marketing e Estados. Do modelo inicial foram retiradas as covariáveis Gastos com Administração e as dummies relacionadas aos estados, assim como as observações 47 e 50, que apresentaram forte influência durante as análises. Aproximadamente $96\%$ da da variação de y, é explicado pelas covariáveis, o que indica um bom ajuste do modelo. Também pode-se concluir que as covariáveis influenciam positivamente na média de $y$, assim como o intercepto.


# Bibliografia

```{r}

```
